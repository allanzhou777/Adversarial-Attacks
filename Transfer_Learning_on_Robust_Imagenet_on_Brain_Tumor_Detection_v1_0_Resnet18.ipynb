{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allanzhou777/Adversarial-Attacks/blob/main/Transfer_Learning_on_Robust_Imagenet_on_Brain_Tumor_Detection_v1_0_Resnet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw0440-vEo_d",
        "outputId": "28a65b25-99e1-473e-d732-aaaa80a718ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting cox\n",
            "  Downloading cox-0.1.post3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cox) (4.65.0)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (from cox) (1.56.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from cox) (5.9.5)\n",
            "Collecting gitpython (from cox)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py3nvml (from cox)\n",
            "  Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython->cox)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xmltodict (from py3nvml->cox)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->cox)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: xmltodict, smmap, py3nvml, gitdb, gitpython, cox\n",
            "Successfully installed cox-0.1.post3 gitdb-4.0.10 gitpython-3.1.31 py3nvml-0.2.7 smmap-5.0.0 xmltodict-0.13.0\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Collecting protobuf>=4.22.3 (from tensorboardX)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, tensorboardX\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "Successfully installed protobuf-4.23.4 tensorboardX-2.6.1\n",
            "Collecting apex\n",
            "  Downloading apex-0.9.10dev.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cryptacular (from apex)\n",
            "  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zope.sqlalchemy (from apex)\n",
            "  Downloading zope.sqlalchemy-3.0-py3-none-any.whl (23 kB)\n",
            "Collecting velruse>=1.0.3 (from apex)\n",
            "  Downloading velruse-1.1.1.tar.gz (709 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.8/709.8 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyramid>1.1.2 (from apex)\n",
            "  Downloading pyramid-2.0.1-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyramid_mailer (from apex)\n",
            "  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from apex) (2.27.1)\n",
            "Collecting wtforms (from apex)\n",
            "  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.5/136.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wtforms-recaptcha (from apex)\n",
            "  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting hupper>=1.5 (from pyramid>1.1.2->apex)\n",
            "  Downloading hupper-1.12-py3-none-any.whl (22 kB)\n",
            "Collecting plaster (from pyramid>1.1.2->apex)\n",
            "  Downloading plaster-1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting plaster-pastedeploy (from pyramid>1.1.2->apex)\n",
            "  Downloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyramid>1.1.2->apex) (67.7.2)\n",
            "Collecting translationstring>=0.4 (from pyramid>1.1.2->apex)\n",
            "  Downloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\n",
            "Collecting venusian>=1.0 (from pyramid>1.1.2->apex)\n",
            "  Downloading venusian-3.0.0-py3-none-any.whl (13 kB)\n",
            "Collecting webob>=1.8.3 (from pyramid>1.1.2->apex)\n",
            "  Downloading WebOb-1.8.7-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.deprecation>=3.5.0 (from pyramid>1.1.2->apex)\n",
            "  Downloading zope.deprecation-5.0-py3-none-any.whl (10 kB)\n",
            "Collecting zope.interface>=3.8.0 (from pyramid>1.1.2->apex)\n",
            "  Downloading zope.interface-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from velruse>=1.0.3->apex) (1.3.1)\n",
            "Collecting anykeystore (from velruse>=1.0.3->apex)\n",
            "  Downloading anykeystore-0.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python3-openid (from velruse>=1.0.3->apex)\n",
            "  Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pbkdf2 (from cryptacular->apex)\n",
            "  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting repoze.sendmail>=4.1 (from pyramid_mailer->apex)\n",
            "  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transaction (from pyramid_mailer->apex)\n",
            "  Downloading transaction-3.1.0-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->apex) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->apex) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->apex) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->apex) (3.4)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.10/dist-packages (from wtforms->apex) (2.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from zope.sqlalchemy->apex) (23.1)\n",
            "Requirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from zope.sqlalchemy->apex) (2.0.16)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex) (4.6.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex) (2.0.2)\n",
            "Collecting PasteDeploy>=2.0 (from plaster-pastedeploy->pyramid>1.1.2->apex)\n",
            "  Downloading PasteDeploy-3.0.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from python3-openid->velruse>=1.0.3->apex) (0.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib->velruse>=1.0.3->apex) (3.2.2)\n",
            "Building wheels for collected packages: apex, velruse, cryptacular, anykeystore, pbkdf2\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46443 sha256=6591bdd36fc76c5a40a4069eafec499ff6a331637db97b7b2a8b21342011ddf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/62/59/9b100fce7ebd989603b3b7a4ca259150da72c9e107fcaa2a30\n",
            "  Building wheel for velruse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50910 sha256=bbd47a2973a62eadb8db466b89bbf144c4149d7382a66f7ee31060535a54689a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/f9/a4/fc4ea7b935ee9c58b9bc772cabd94f6a8560f35444097d948d\n",
            "  Building wheel for cryptacular (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp310-cp310-linux_x86_64.whl size=58181 sha256=4b2c9437b70bc0399616286781b701f09ee15d45294fd040483aa8a20c219304\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/6e/09/a7fba517f95b2a6a36bd01b6d4f4679fa7259615a493b64b8f\n",
            "  Building wheel for anykeystore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=16814 sha256=8e4a11a11668a2f739bd42541c293d76664e46bf4e783e089d7ac8af2a9649e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/9e/24/35542b7d376b53a6f8426524cc5a3f7998f975037b32d19906\n",
            "  Building wheel for pbkdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5081 sha256=a3d0990d49a1fb9a07db7a14bb3959587e82954ad84c00cd8263f009a0522d64\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/7d/8b/4269ff90fda80497ec59f6ff7d1e1596cb697c1dc8e9bbe320\n",
            "Successfully built apex velruse cryptacular anykeystore pbkdf2\n",
            "Installing collected packages: translationstring, pbkdf2, anykeystore, zope.interface, zope.deprecation, wtforms, webob, venusian, python3-openid, plaster, PasteDeploy, hupper, cryptacular, wtforms-recaptcha, transaction, plaster-pastedeploy, zope.sqlalchemy, repoze.sendmail, pyramid, velruse, pyramid_mailer, apex\n",
            "Successfully installed PasteDeploy-3.0.1 anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.6.2 hupper-1.12 pbkdf2-1.3 plaster-1.1.2 plaster-pastedeploy-1.0.1 pyramid-2.0.1 pyramid_mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 transaction-3.1.0 translationstring-1.4 velruse-1.1.1 venusian-3.0.0 webob-1.8.7 wtforms-3.0.1 wtforms-recaptcha-0.3.2 zope.deprecation-5.0 zope.interface-6.0 zope.sqlalchemy-3.0\n",
            "Cloning into 'robustness'...\n",
            "remote: Enumerating objects: 927, done.\u001b[K\n",
            "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 927 (delta 110), reused 146 (delta 101), pack-reused 758\u001b[K\n",
            "Receiving objects: 100% (927/927), 6.52 MiB | 22.40 MiB/s, done.\n",
            "Resolving deltas: 100% (618/618), done.\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.3.6\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19867 sha256=d36f8927b0d5f6a3f1d83af04ea0d6feaff98e8198011ffb0943931ba15574e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/42/78/0c3d438d7f5730451a25f7ac6cbf4391759d22a67576ed7c2c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/robustness/robustness/train.py:24: UserWarning: Could not import amp.\n",
            "  warnings.warn('Could not import amp.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current directory/content/robustness\n",
            "Archive:  /content/Brain-Tumor-Detection.zip\n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/1 no.jpeg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/10 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/11 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/12 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/13 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/14 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/15 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/17 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/18 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/19 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/2 no.jpeg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/20 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/21 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/22 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/23 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/24 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/25 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/26 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/27 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/28 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/29 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/3 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/30 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/31 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/32 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/33 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/34 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/35 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/36 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/37 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/38 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/39 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/4 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/40 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/41 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/42 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/43 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/44no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/45 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/46 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/47 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/48 no.jpeg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/49 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/5 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/50 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/6 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/7 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/8 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/9 no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N1.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N11.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N15.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N16.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N17.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N19.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N2.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N20.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N21.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N22.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N26.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N3.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N5.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/N6.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No11.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No12.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No13.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No14.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No15.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No16.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No17.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No18.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No19.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No20.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No21.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/No22.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 1.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 10.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 100.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 2.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 3.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 4.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 5.jpeg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 6.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 7.jpeg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 8.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 89.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 9.png  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 90.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 91.jpeg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 92.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 923.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 94.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 95.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 96.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 97.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 98.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no 99.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/no/no.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y1.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y10.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y100.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y101.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y102.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y103.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y104.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y105.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y106.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y107.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y108.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y109.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y11.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y111.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y112.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y113.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y114.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y115.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y116.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y117.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y12.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y120.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y13.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y14.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y146.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y147.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y148.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y15.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y153.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y154.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y155.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y156.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y157.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y158.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y159.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y16.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y160.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y161.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y162.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y163.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y164.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y165.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y166.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y167.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y168.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y169.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y17.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y170.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y18.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y180.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y181.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y182.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y183.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y184.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y185.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y186.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y187.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y188.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y19.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y192.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y193.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y194.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y195.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y2.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y20.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y21.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y22.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y23.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y24.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y242.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y243.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y244.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y245.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y246.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y247.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y248.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y249.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y25.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y250.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y251.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y252.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y253.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y254.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y255.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y256.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y257.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y258.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y259.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y26.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y27.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y28.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y29.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y3.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y30.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y31.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y32.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y33.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y34.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y35.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y36.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y37.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y38.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y39.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y4.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y40.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y41.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y42.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y44.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y45.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y46.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y47.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y49.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y50.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y51.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y52.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y53.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y54.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y55.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y56.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y58.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y59.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y6.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y60.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y61.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y62.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y65.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y66.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y67.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y69.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y7.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y70.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y71.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y73.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y74.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y75.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y76.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y77.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y78.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y79.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y8.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y81.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y82.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y85.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y86.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y89.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y9.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y90.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y91.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y92.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y92.png  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y95.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y96.jpg  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y97.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y98.JPG  \n",
            "  inflating: /content/dataset/brain_tumor_dataset/yes/Y99.JPG  \n",
            "  inflating: /content/dataset/no/1 no.jpeg  \n",
            "  inflating: /content/dataset/no/10 no.jpg  \n",
            "  inflating: /content/dataset/no/11 no.jpg  \n",
            "  inflating: /content/dataset/no/12 no.jpg  \n",
            "  inflating: /content/dataset/no/13 no.jpg  \n",
            "  inflating: /content/dataset/no/14 no.jpg  \n",
            "  inflating: /content/dataset/no/15 no.jpg  \n",
            "  inflating: /content/dataset/no/17 no.jpg  \n",
            "  inflating: /content/dataset/no/18 no.jpg  \n",
            "  inflating: /content/dataset/no/19 no.jpg  \n",
            "  inflating: /content/dataset/no/2 no.jpeg  \n",
            "  inflating: /content/dataset/no/20 no.jpg  \n",
            "  inflating: /content/dataset/no/21 no.jpg  \n",
            "  inflating: /content/dataset/no/22 no.jpg  \n",
            "  inflating: /content/dataset/no/23 no.jpg  \n",
            "  inflating: /content/dataset/no/24 no.jpg  \n",
            "  inflating: /content/dataset/no/25 no.jpg  \n",
            "  inflating: /content/dataset/no/26 no.jpg  \n",
            "  inflating: /content/dataset/no/27 no.jpg  \n",
            "  inflating: /content/dataset/no/28 no.jpg  \n",
            "  inflating: /content/dataset/no/29 no.jpg  \n",
            "  inflating: /content/dataset/no/3 no.jpg  \n",
            "  inflating: /content/dataset/no/30 no.jpg  \n",
            "  inflating: /content/dataset/no/31 no.jpg  \n",
            "  inflating: /content/dataset/no/32 no.jpg  \n",
            "  inflating: /content/dataset/no/33 no.jpg  \n",
            "  inflating: /content/dataset/no/34 no.jpg  \n",
            "  inflating: /content/dataset/no/35 no.jpg  \n",
            "  inflating: /content/dataset/no/36 no.jpg  \n",
            "  inflating: /content/dataset/no/37 no.jpg  \n",
            "  inflating: /content/dataset/no/38 no.jpg  \n",
            "  inflating: /content/dataset/no/39 no.jpg  \n",
            "  inflating: /content/dataset/no/4 no.jpg  \n",
            "  inflating: /content/dataset/no/40 no.jpg  \n",
            "  inflating: /content/dataset/no/41 no.jpg  \n",
            "  inflating: /content/dataset/no/42 no.jpg  \n",
            "  inflating: /content/dataset/no/43 no.jpg  \n",
            "  inflating: /content/dataset/no/44no.jpg  \n",
            "  inflating: /content/dataset/no/45 no.jpg  \n",
            "  inflating: /content/dataset/no/46 no.jpg  \n",
            "  inflating: /content/dataset/no/47 no.jpg  \n",
            "  inflating: /content/dataset/no/48 no.jpeg  \n",
            "  inflating: /content/dataset/no/49 no.jpg  \n",
            "  inflating: /content/dataset/no/5 no.jpg  \n",
            "  inflating: /content/dataset/no/50 no.jpg  \n",
            "  inflating: /content/dataset/no/6 no.jpg  \n",
            "  inflating: /content/dataset/no/7 no.jpg  \n",
            "  inflating: /content/dataset/no/8 no.jpg  \n",
            "  inflating: /content/dataset/no/9 no.jpg  \n",
            "  inflating: /content/dataset/no/N1.JPG  \n",
            "  inflating: /content/dataset/no/N11.jpg  \n",
            "  inflating: /content/dataset/no/N15.jpg  \n",
            "  inflating: /content/dataset/no/N16.jpg  \n",
            "  inflating: /content/dataset/no/N17.jpg  \n",
            "  inflating: /content/dataset/no/N19.JPG  \n",
            "  inflating: /content/dataset/no/N2.JPG  \n",
            "  inflating: /content/dataset/no/N20.JPG  \n",
            "  inflating: /content/dataset/no/N21.jpg  \n",
            "  inflating: /content/dataset/no/N22.JPG  \n",
            "  inflating: /content/dataset/no/N26.JPG  \n",
            "  inflating: /content/dataset/no/N3.jpg  \n",
            "  inflating: /content/dataset/no/N5.jpg  \n",
            "  inflating: /content/dataset/no/N6.jpg  \n",
            "  inflating: /content/dataset/no/No11.jpg  \n",
            "  inflating: /content/dataset/no/No12.jpg  \n",
            "  inflating: /content/dataset/no/No13.jpg  \n",
            "  inflating: /content/dataset/no/No14.jpg  \n",
            "  inflating: /content/dataset/no/No15.jpg  \n",
            "  inflating: /content/dataset/no/No16.jpg  \n",
            "  inflating: /content/dataset/no/No17.jpg  \n",
            "  inflating: /content/dataset/no/No18.jpg  \n",
            "  inflating: /content/dataset/no/No19.jpg  \n",
            "  inflating: /content/dataset/no/No20.jpg  \n",
            "  inflating: /content/dataset/no/No21.jpg  \n",
            "  inflating: /content/dataset/no/No22.jpg  \n",
            "  inflating: /content/dataset/no/no 1.jpg  \n",
            "  inflating: /content/dataset/no/no 10.jpg  \n",
            "  inflating: /content/dataset/no/no 100.jpg  \n",
            "  inflating: /content/dataset/no/no 2.jpg  \n",
            "  inflating: /content/dataset/no/no 3.jpg  \n",
            "  inflating: /content/dataset/no/no 4.jpg  \n",
            "  inflating: /content/dataset/no/no 5.jpeg  \n",
            "  inflating: /content/dataset/no/no 6.jpg  \n",
            "  inflating: /content/dataset/no/no 7.jpeg  \n",
            "  inflating: /content/dataset/no/no 8.jpg  \n",
            "  inflating: /content/dataset/no/no 89.jpg  \n",
            "  inflating: /content/dataset/no/no 9.png  \n",
            "  inflating: /content/dataset/no/no 90.jpg  \n",
            "  inflating: /content/dataset/no/no 91.jpeg  \n",
            "  inflating: /content/dataset/no/no 92.jpg  \n",
            "  inflating: /content/dataset/no/no 923.jpg  \n",
            "  inflating: /content/dataset/no/no 94.jpg  \n",
            "  inflating: /content/dataset/no/no 95.jpg  \n",
            "  inflating: /content/dataset/no/no 96.jpg  \n",
            "  inflating: /content/dataset/no/no 97.jpg  \n",
            "  inflating: /content/dataset/no/no 98.jpg  \n",
            "  inflating: /content/dataset/no/no 99.jpg  \n",
            "  inflating: /content/dataset/no/no.jpg  \n",
            "  inflating: /content/dataset/yes/Y1.jpg  \n",
            "  inflating: /content/dataset/yes/Y10.jpg  \n",
            "  inflating: /content/dataset/yes/Y100.JPG  \n",
            "  inflating: /content/dataset/yes/Y101.jpg  \n",
            "  inflating: /content/dataset/yes/Y102.jpg  \n",
            "  inflating: /content/dataset/yes/Y103.jpg  \n",
            "  inflating: /content/dataset/yes/Y104.jpg  \n",
            "  inflating: /content/dataset/yes/Y105.jpg  \n",
            "  inflating: /content/dataset/yes/Y106.jpg  \n",
            "  inflating: /content/dataset/yes/Y107.jpg  \n",
            "  inflating: /content/dataset/yes/Y108.jpg  \n",
            "  inflating: /content/dataset/yes/Y109.JPG  \n",
            "  inflating: /content/dataset/yes/Y11.jpg  \n",
            "  inflating: /content/dataset/yes/Y111.JPG  \n",
            "  inflating: /content/dataset/yes/Y112.JPG  \n",
            "  inflating: /content/dataset/yes/Y113.JPG  \n",
            "  inflating: /content/dataset/yes/Y114.JPG  \n",
            "  inflating: /content/dataset/yes/Y115.JPG  \n",
            "  inflating: /content/dataset/yes/Y116.JPG  \n",
            "  inflating: /content/dataset/yes/Y117.JPG  \n",
            "  inflating: /content/dataset/yes/Y12.jpg  \n",
            "  inflating: /content/dataset/yes/Y120.JPG  \n",
            "  inflating: /content/dataset/yes/Y13.jpg  \n",
            "  inflating: /content/dataset/yes/Y14.jpg  \n",
            "  inflating: /content/dataset/yes/Y146.JPG  \n",
            "  inflating: /content/dataset/yes/Y147.JPG  \n",
            "  inflating: /content/dataset/yes/Y148.JPG  \n",
            "  inflating: /content/dataset/yes/Y15.jpg  \n",
            "  inflating: /content/dataset/yes/Y153.jpg  \n",
            "  inflating: /content/dataset/yes/Y154.jpg  \n",
            "  inflating: /content/dataset/yes/Y155.JPG  \n",
            "  inflating: /content/dataset/yes/Y156.JPG  \n",
            "  inflating: /content/dataset/yes/Y157.JPG  \n",
            "  inflating: /content/dataset/yes/Y158.JPG  \n",
            "  inflating: /content/dataset/yes/Y159.JPG  \n",
            "  inflating: /content/dataset/yes/Y16.JPG  \n",
            "  inflating: /content/dataset/yes/Y160.JPG  \n",
            "  inflating: /content/dataset/yes/Y161.JPG  \n",
            "  inflating: /content/dataset/yes/Y162.jpg  \n",
            "  inflating: /content/dataset/yes/Y163.JPG  \n",
            "  inflating: /content/dataset/yes/Y164.JPG  \n",
            "  inflating: /content/dataset/yes/Y165.JPG  \n",
            "  inflating: /content/dataset/yes/Y166.JPG  \n",
            "  inflating: /content/dataset/yes/Y167.JPG  \n",
            "  inflating: /content/dataset/yes/Y168.jpg  \n",
            "  inflating: /content/dataset/yes/Y169.jpg  \n",
            "  inflating: /content/dataset/yes/Y17.jpg  \n",
            "  inflating: /content/dataset/yes/Y170.JPG  \n",
            "  inflating: /content/dataset/yes/Y18.JPG  \n",
            "  inflating: /content/dataset/yes/Y180.jpg  \n",
            "  inflating: /content/dataset/yes/Y181.jpg  \n",
            "  inflating: /content/dataset/yes/Y182.JPG  \n",
            "  inflating: /content/dataset/yes/Y183.jpg  \n",
            "  inflating: /content/dataset/yes/Y184.JPG  \n",
            "  inflating: /content/dataset/yes/Y185.jpg  \n",
            "  inflating: /content/dataset/yes/Y186.jpg  \n",
            "  inflating: /content/dataset/yes/Y187.jpg  \n",
            "  inflating: /content/dataset/yes/Y188.jpg  \n",
            "  inflating: /content/dataset/yes/Y19.JPG  \n",
            "  inflating: /content/dataset/yes/Y192.JPG  \n",
            "  inflating: /content/dataset/yes/Y193.JPG  \n",
            "  inflating: /content/dataset/yes/Y194.jpg  \n",
            "  inflating: /content/dataset/yes/Y195.JPG  \n",
            "  inflating: /content/dataset/yes/Y2.jpg  \n",
            "  inflating: /content/dataset/yes/Y20.jpg  \n",
            "  inflating: /content/dataset/yes/Y21.jpg  \n",
            "  inflating: /content/dataset/yes/Y22.jpg  \n",
            "  inflating: /content/dataset/yes/Y23.JPG  \n",
            "  inflating: /content/dataset/yes/Y24.jpg  \n",
            "  inflating: /content/dataset/yes/Y242.JPG  \n",
            "  inflating: /content/dataset/yes/Y243.JPG  \n",
            "  inflating: /content/dataset/yes/Y244.JPG  \n",
            "  inflating: /content/dataset/yes/Y245.jpg  \n",
            "  inflating: /content/dataset/yes/Y246.JPG  \n",
            "  inflating: /content/dataset/yes/Y247.JPG  \n",
            "  inflating: /content/dataset/yes/Y248.JPG  \n",
            "  inflating: /content/dataset/yes/Y249.JPG  \n",
            "  inflating: /content/dataset/yes/Y25.jpg  \n",
            "  inflating: /content/dataset/yes/Y250.jpg  \n",
            "  inflating: /content/dataset/yes/Y251.JPG  \n",
            "  inflating: /content/dataset/yes/Y252.jpg  \n",
            "  inflating: /content/dataset/yes/Y253.JPG  \n",
            "  inflating: /content/dataset/yes/Y254.jpg  \n",
            "  inflating: /content/dataset/yes/Y255.JPG  \n",
            "  inflating: /content/dataset/yes/Y256.JPG  \n",
            "  inflating: /content/dataset/yes/Y257.jpg  \n",
            "  inflating: /content/dataset/yes/Y258.JPG  \n",
            "  inflating: /content/dataset/yes/Y259.JPG  \n",
            "  inflating: /content/dataset/yes/Y26.jpg  \n",
            "  inflating: /content/dataset/yes/Y27.jpg  \n",
            "  inflating: /content/dataset/yes/Y28.jpg  \n",
            "  inflating: /content/dataset/yes/Y29.jpg  \n",
            "  inflating: /content/dataset/yes/Y3.jpg  \n",
            "  inflating: /content/dataset/yes/Y30.jpg  \n",
            "  inflating: /content/dataset/yes/Y31.jpg  \n",
            "  inflating: /content/dataset/yes/Y32.jpg  \n",
            "  inflating: /content/dataset/yes/Y33.jpg  \n",
            "  inflating: /content/dataset/yes/Y34.jpg  \n",
            "  inflating: /content/dataset/yes/Y35.jpg  \n",
            "  inflating: /content/dataset/yes/Y36.JPG  \n",
            "  inflating: /content/dataset/yes/Y37.jpg  \n",
            "  inflating: /content/dataset/yes/Y38.jpg  \n",
            "  inflating: /content/dataset/yes/Y39.jpg  \n",
            "  inflating: /content/dataset/yes/Y4.jpg  \n",
            "  inflating: /content/dataset/yes/Y40.JPG  \n",
            "  inflating: /content/dataset/yes/Y41.jpg  \n",
            "  inflating: /content/dataset/yes/Y42.jpg  \n",
            "  inflating: /content/dataset/yes/Y44.JPG  \n",
            "  inflating: /content/dataset/yes/Y45.JPG  \n",
            "  inflating: /content/dataset/yes/Y46.jpg  \n",
            "  inflating: /content/dataset/yes/Y47.JPG  \n",
            "  inflating: /content/dataset/yes/Y49.JPG  \n",
            "  inflating: /content/dataset/yes/Y50.JPG  \n",
            "  inflating: /content/dataset/yes/Y51.jpg  \n",
            "  inflating: /content/dataset/yes/Y52.jpg  \n",
            "  inflating: /content/dataset/yes/Y53.jpg  \n",
            "  inflating: /content/dataset/yes/Y54.jpg  \n",
            "  inflating: /content/dataset/yes/Y55.jpg  \n",
            "  inflating: /content/dataset/yes/Y56.jpg  \n",
            "  inflating: /content/dataset/yes/Y58.JPG  \n",
            "  inflating: /content/dataset/yes/Y59.JPG  \n",
            "  inflating: /content/dataset/yes/Y6.jpg  \n",
            "  inflating: /content/dataset/yes/Y60.jpg  \n",
            "  inflating: /content/dataset/yes/Y61.jpg  \n",
            "  inflating: /content/dataset/yes/Y62.jpg  \n",
            "  inflating: /content/dataset/yes/Y65.JPG  \n",
            "  inflating: /content/dataset/yes/Y66.JPG  \n",
            "  inflating: /content/dataset/yes/Y67.JPG  \n",
            "  inflating: /content/dataset/yes/Y69.jpg  \n",
            "  inflating: /content/dataset/yes/Y7.jpg  \n",
            "  inflating: /content/dataset/yes/Y70.jpg  \n",
            "  inflating: /content/dataset/yes/Y71.JPG  \n",
            "  inflating: /content/dataset/yes/Y73.jpg  \n",
            "  inflating: /content/dataset/yes/Y74.jpg  \n",
            "  inflating: /content/dataset/yes/Y75.JPG  \n",
            "  inflating: /content/dataset/yes/Y76.jpg  \n",
            "  inflating: /content/dataset/yes/Y77.jpg  \n",
            "  inflating: /content/dataset/yes/Y78.jpg  \n",
            "  inflating: /content/dataset/yes/Y79.jpg  \n",
            "  inflating: /content/dataset/yes/Y8.jpg  \n",
            "  inflating: /content/dataset/yes/Y81.jpg  \n",
            "  inflating: /content/dataset/yes/Y82.jpg  \n",
            "  inflating: /content/dataset/yes/Y85.JPG  \n",
            "  inflating: /content/dataset/yes/Y86.JPG  \n",
            "  inflating: /content/dataset/yes/Y89.JPG  \n",
            "  inflating: /content/dataset/yes/Y9.jpg  \n",
            "  inflating: /content/dataset/yes/Y90.jpg  \n",
            "  inflating: /content/dataset/yes/Y91.jpg  \n",
            "  inflating: /content/dataset/yes/Y92.jpg  \n",
            "  inflating: /content/dataset/yes/Y92.png  \n",
            "  inflating: /content/dataset/yes/Y95.jpg  \n",
            "  inflating: /content/dataset/yes/Y96.jpg  \n",
            "  inflating: /content/dataset/yes/Y97.JPG  \n",
            "  inflating: /content/dataset/yes/Y98.JPG  \n",
            "  inflating: /content/dataset/yes/Y99.JPG  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install cox\n",
        "!pip install tensorboardX\n",
        "!pip install apex\n",
        "!git clone https://github.com/MadryLab/robustness.git\n",
        "!pip install dill\n",
        "!pip install pyngrok\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/robustness/\")\n",
        "import torch\n",
        "import torch as ch\n",
        "from torch import nn\n",
        "\n",
        "import dill\n",
        "\n",
        "from cox.utils import Parameters\n",
        "from cox.readers import CollectionReader\n",
        "import cox.store\n",
        "import copy\n",
        "from robustness import imagenet_models # or cifar_models\n",
        "from robustness import model_utils, train, defaults\n",
        "\n",
        "from robustness.attacker import AttackerModel\n",
        "from robustness.datasets import ImageNet\n",
        "from robustness.datasets import DATASETS\n",
        "# from robustness.datasets import MyNewDataSet\n",
        "from robustness.model_utils import make_and_restore_model\n",
        "from robustness.defaults import check_and_fill_args\n",
        "from robustness.tools import constants, helpers\n",
        "from robustness.tools.custom_modules import SequentialWithArgs\n",
        "from torchvision.models import resnet18\n",
        "from robustness.model_utils import make_and_restore_model\n",
        "from argparse import ArgumentParser\n",
        "import datetime\n",
        "from fractions import Fraction\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "CURRENT_DIRECTORY = os.getcwd()\n",
        "print(f'current directory{CURRENT_DIRECTORY}')\n",
        "\n",
        "# CONSTANTS\n",
        "IMAGES_PATH = '/content/dataset/brain_tumor_dataset/'\n",
        "\n",
        "\n",
        "# unzip Radiography dataset\n",
        "!cp /content/drive/MyDrive/Adversarial\\ Attacks/datasets/Brain\\ Tumor\\ Detection/Brain-Tumor-Detection.zip /content/\n",
        "!unzip /content/Brain-Tumor-Detection.zip -d /content/dataset/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy0BXTS8EQe3"
      },
      "source": [
        "## Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqU_tRMeEQe3"
      },
      "outputs": [],
      "source": [
        "#first bracket: eps-train; second bracket: eps-test\n",
        "L2_EVAL = 'l2_eval_{}_{}/'\n",
        "L_INF_EVAL = 'l_inf_eval_{}_{}/'\n",
        "UNCONSTRAINED_EVAL = 'unconstrained_eval/'\n",
        "FOURIER_EVAL = 'fourier_eval/'\n",
        "RANDOM_EVAL = 'random_eval/'\n",
        "\n",
        "\n",
        "#HELPER FUNCTIONS\n",
        "calc_attack_lr = lambda eps_test, steps: 2.5 * eps_test / steps\n",
        "\n",
        "\n",
        "def setup_store_with_metadata(args):\n",
        "    '''\n",
        "    Sets up a store for training according to the arguments object. See the\n",
        "    argparse object above for options.\n",
        "    '''\n",
        "    # Create the store\n",
        "    store = cox.store.Store(args.out_dir, args.exp_name)\n",
        "    args_dict = args.__dict__\n",
        "    schema = cox.store.schema_from_dict(args_dict)\n",
        "    store.add_table('metadata', schema)\n",
        "    store['metadata'].append_row(args_dict)\n",
        "\n",
        "    return store\n",
        "\n",
        "\n",
        "def evaluate_robust_model(eval_args,\n",
        "                          model,\n",
        "                          test_out_dir,\n",
        "                          attack_steps=[20]):\n",
        "  '''\n",
        "  Evaluates a robust neural network on adversarial attacks. Stores results in Store in test_out_dir.\n",
        "  Args:\n",
        "    eval_args: (cox.utils.Parameters) hyperparameters used to evaluate the robust model\n",
        "        https://github.com/MadryLab/robustness/blob/master/robustness/defaults.py#L91\n",
        "    model: (robustness.attacker.AttackerModel) robust neural network\n",
        "    test_out_dir: (str) where evaluation results are stored\n",
        "    attack_steps: (optional, list) stores options for number of attack steps\n",
        "  Returns: None\n",
        "  '''\n",
        "  assert eval_args.__contains__('eps'), \"eps value required in eval_args parameter\"\n",
        "  assert eval_args.__contains__('constraint'), \"constraint value required in eval_args parameter\"\n",
        "\n",
        "  for atk_steps in attack_steps:\n",
        "    print('evaluating robust model with constaint: {}, eps: {}, and attack steps: {}'.format(eval_args.constraint,\n",
        "                                                              Fraction(eval_args.eps).limit_denominator(),\n",
        "                                                              atk_steps))\n",
        "\n",
        "    eval_args.__setattr__('attack_steps', atk_steps)\n",
        "    eval_args.__setattr__('attack_lr', calc_attack_lr(eval_args.__getattr__('eps'),\n",
        "                                                    eval_args.__getattr__('attack_steps')))\n",
        "    eval_args.__setattr__('out_dir', test_out_dir)\n",
        "\n",
        "    # check whether the evaluation args provided are correct\n",
        "    train.check_required_args(eval_args, eval_only=True)\n",
        "    test_loader = copy.copy(val_loader)\n",
        "    print(f'test results dir: {test_out_dir}')\n",
        "\n",
        "    test_store = setup_store_with_metadata(eval_args)\n",
        "\n",
        "    train.eval_model(eval_args, model, test_loader, test_store)\n",
        "    test_store.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DAbiULV1EzA"
      },
      "outputs": [],
      "source": [
        "def load_split_train_test(args, datadir, valid_size = .2):\n",
        "    train_data = datasets.ImageFolder(datadir,\n",
        "                    transform=data_transforms['train']) #Picks up Image Paths from its respective folders and label them\n",
        "    test_data = datasets.ImageFolder(datadir,\n",
        "                    transform=data_transforms['val'])\n",
        "    num_train = len(train_data)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    np.random.shuffle(indices)\n",
        "    train_idx, test_idx = indices[split:], indices[:split]\n",
        "    dataset_size = {\"train\":len(train_idx), \"val\":len(test_idx)}\n",
        "    train_sampler = SubsetRandomSampler(train_idx) # Sampler for splitting train and val images\n",
        "    test_sampler = SubsetRandomSampler(test_idx)\n",
        "    trainloader = ch.utils.data.DataLoader(train_data,\n",
        "                   sampler=train_sampler, batch_size=args.batch_size) # DataLoader provides data from traininng and validation in batches\n",
        "    testloader = ch.utils.data.DataLoader(test_data,\n",
        "                   sampler=test_sampler, batch_size=args.batch_size)\n",
        "    return trainloader, testloader, dataset_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5gz2qZN2wGS"
      },
      "outputs": [],
      "source": [
        "def ft(model_name, model_ft, num_classes, additional_hidden=0):\n",
        "    if model_name in [\"resnet\", \"resnet18\", \"resnet50\", \"wide_resnet50_2\", \"wide_resnet50_4\", \"resnext50_32x4d\", 'shufflenet']:\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        # The two cases are split just to allow loading\n",
        "        # models trained prior to adding the additional_hidden argument\n",
        "        # without errors\n",
        "        if additional_hidden == 0:\n",
        "            model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        else:\n",
        "            model_ft.fc = SequentialWithArgs(\n",
        "                *list(sum([[nn.Linear(num_ftrs, num_ftrs), nn.ReLU()] for i in range(additional_hidden)], [])),\n",
        "                nn.Linear(num_ftrs, num_classes)\n",
        "            )\n",
        "        input_size = 224\n",
        "    elif model_name == \"alexnet\":\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "    elif \"vgg\" in model_name:\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "    elif model_name == \"squeezenet\":\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "    elif model_name == \"densenet\":\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "    elif model_name in [\"mnasnet\", \"mobilenet\"]:\n",
        "        num_ftrs = model_ft.classifier[1].in_features\n",
        "        model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model type, exiting...\")\n",
        "\n",
        "    return model_ft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2VtG1WHEQe3"
      },
      "outputs": [],
      "source": [
        "eval_args = Parameters({\n",
        "    'adv_eval': 1,\n",
        "    'eval_only': 1,\n",
        "    'use_best': True,\n",
        "    'random_restarts': 0,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37bibnfQ6_IS"
      },
      "outputs": [],
      "source": [
        "BLUE_SHADE = 'rgba(0, 0, 255, .2)'\n",
        "RED_SHADE = 'rgba(255, 0, 0, .2)'\n",
        "YELLOW_SHADE = 'rgba(255,255,0,0.2)'\n",
        "PURPLE_SHADE = 'rgba(216,191,216,0.2)'\n",
        "GREEN_SHADE = 'rgba(0,128,0, .2)'\n",
        "ORANGE_SHADE = 'rgba(255,128,0, .2)'\n",
        "\n",
        "\n",
        "colors = ['red', 'blue', 'green', 'orange']\n",
        "def measurement_scatter(mean: pd.Series,\n",
        "                        x: pd.Series,\n",
        "                        upper: pd.Series,\n",
        "                        lower: pd.Series,\n",
        "                        col: str,\n",
        "                        title: str,\n",
        "                        color: str):\n",
        "\n",
        "\n",
        "  shade = BLUE_SHADE\n",
        "  if color == 'red':\n",
        "    shade = RED_SHADE\n",
        "  elif color == 'yellow':\n",
        "    shade = YELLOW_SHADE\n",
        "  elif color == 'purple':\n",
        "    shade = PURPLE_SHADE\n",
        "  elif color == 'green':\n",
        "    shade = GREEN_SHADE\n",
        "  elif color == 'orange':\n",
        "    shade = ORANGE_SHADE\n",
        "  return [go.Scatter(\n",
        "        x=x,\n",
        "        y=mean,\n",
        "        line=dict(color=color),\n",
        "        mode='lines+markers',\n",
        "        name=title,\n",
        "    )]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya3KcPGGUxTR"
      },
      "outputs": [],
      "source": [
        "#parser\n",
        "parser = ArgumentParser()\n",
        "parser.add_argument('-f')\n",
        "parser = defaults.add_args_to_parser(defaults.MODEL_LOADER_ARGS, parser)\n",
        "parser = defaults.add_args_to_parser(defaults.TRAINING_ARGS, parser)\n",
        "parser = defaults.add_args_to_parser(defaults.PGD_ARGS, parser)\n",
        "# Note that we can add whatever extra arguments we want to the parser here\n",
        "args = parser.parse_args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_EiDS53wLF5"
      },
      "outputs": [],
      "source": [
        "#Statistics Based on ImageNet Data for Normalisation\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "mean_nums = [0.485, 0.456, 0.406]\n",
        "std_nums = [0.229, 0.224, 0.225]\n",
        "\n",
        "data_transforms = {\"train\":transforms.Compose([\n",
        "                                transforms.Resize((150,150)), #Resizes all images into same dimension\n",
        "                                # transforms.RandomRotation(10), # Rotates the images upto Max of 10 Degrees\n",
        "                                # transforms.RandomHorizontalFlip(p=0.4), #Performs Horizantal Flip over images\n",
        "                                transforms.ToTensor(), # Coverts into Tensors\n",
        "                                #transforms.Normalize(mean = mean_nums, std=std_nums)\n",
        "                    ]), # Normalizes\n",
        "                    \"val\": transforms.Compose([\n",
        "                                transforms.Resize((150,150)),\n",
        "                                transforms.CenterCrop(150), #Performs Crop at Center and resizes it to 150x150\n",
        "                                transforms.ToTensor(),\n",
        "                                # transforms.Normalize(mean=mean_nums, std = std_nums)\n",
        "                    ])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_VWjA12uyvz"
      },
      "outputs": [],
      "source": [
        "ARCH = 'resnet_18'\n",
        "OUT_DIR = '/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/' + ARCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRVsCj4K2Ndo"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41o77hL8UiY3",
        "outputId": "fb8935d9-6a73-46e9-8622-80ef4ed70bbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Arguments:  {\n",
            "  \"adv_train\": 0,\n",
            "  \"dataset\": \"imagenet\",\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18\",\n",
            "  \"arch\": \"resnet18\",\n",
            "  \"epochs\": 20,\n",
            "  \"mixed_precision\": 0,\n",
            "  \"batch_size\": 32,\n",
            "  \"log_iters\": 1,\n",
            "  \"lr\": 0.001,\n",
            "  \"additional_hidden\": 1,\n",
            "  \"weight_decay\": 0.0001,\n",
            "  \"momentum\": 0.9,\n",
            "  \"step_lr\": 50,\n",
            "  \"step_lr_gamma\": 0.1,\n",
            "  \"lr_interpolation\": \"step\",\n",
            "  \"save_ckpt_iters\": -1,\n",
            "  \"data\": \"/tmp/\",\n",
            "  \"workers\": 30,\n",
            "  \"resume_optimizer\": 0,\n",
            "  \"data_aug\": 1\n",
            "}\n",
            "{'adv_train': 0, 'dataset': 'imagenet', 'out_dir': '/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18', 'arch': 'resnet18', 'epochs': 20, 'mixed_precision': 0, 'batch_size': 32, 'log_iters': 1, 'lr': 0.001, 'additional_hidden': 1, 'weight_decay': 0.0001, 'momentum': 0.9, 'step_lr': 50, 'step_lr_gamma': 0.1, 'lr_interpolation': 'step', 'save_ckpt_iters': -1, 'data': '/tmp/', 'workers': 30, 'resume_optimizer': 0, 'data_aug': 1}\n"
          ]
        }
      ],
      "source": [
        "#define default training parameters\n",
        "train_kwargs = {\n",
        "    'adv_train': 0,\n",
        "    'dataset': 'imagenet',\n",
        "    'out_dir': OUT_DIR,\n",
        "    'arch': 'resnet18',\n",
        "    'epochs': 20,\n",
        "    'mixed_precision': 0,\n",
        "    'batch_size': 32,\n",
        "    'log_iters': 1,\n",
        "    'lr': 1e-3,\n",
        "    'additional_hidden': 1,\n",
        "}\n",
        "args = Parameters(train_kwargs)\n",
        "#sanity checks\n",
        "ds_class = DATASETS[args.dataset]\n",
        "assert args.dataset is not None, \"Must provide a dataset\"\n",
        "args = check_and_fill_args(args, defaults.TRAINING_ARGS, ds_class)\n",
        "\n",
        "if args.adv_train or args.adv_eval:\n",
        "  args = check_and_fill_args(args, defaults.PGD_ARGS, ds_class)\n",
        "args = check_and_fill_args(args, defaults.MODEL_LOADER_ARGS, ds_class)\n",
        "print(f'Training Arguments: ', args)\n",
        "print(train_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C-EYnrj1Gw4",
        "outputId": "a9c08d3c-f935-4370-f5a5-05418da5408c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['no', 'yes']\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.ImageFolder(IMAGES_PATH,\n",
        "                    transform=data_transforms['train']) #Picks up Image Paths from its respective folders and label them\n",
        "test_data = datasets.ImageFolder(IMAGES_PATH,\n",
        "                    transform=data_transforms['val'])\n",
        "\n",
        "train_loader, val_loader, dataset_size = load_split_train_test(args, IMAGES_PATH, .2)\n",
        "dataloaders = {\"train\":train_loader, \"val\":val_loader}\n",
        "data_sizes = {x: len(dataloaders[x].sampler) for x in ['train','val']}\n",
        "class_names = train_loader.dataset.classes\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsxIcfqB07Vn"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ257K8i23mL"
      },
      "source": [
        "##Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oatCZcGtzZE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8noMK8gdmXc",
        "outputId": "ffaf6fa6-994b-43cb-e184-a7aa9f49064a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning:\n",
            "\n",
            "Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning:\n",
            "\n",
            "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> loading checkpoint '/content/drive/MyDrive/Adversarial Attacks/Robust ImageNet Transfer Models/resnet18_l2_eps3.ckpt'\n",
            "=> loaded checkpoint '/content/drive/MyDrive/Adversarial Attacks/Robust ImageNet Transfer Models/resnet18_l2_eps3.ckpt' (epoch 90)\n"
          ]
        }
      ],
      "source": [
        "dataset = ImageNet(data_path = \"\")\n",
        "# dataset = MyNewDataSet('/path/to/dataset/') #custom dataset path here\n",
        "imagenet = dataset\n",
        "\n",
        "# model_path = \"resnet18_l2_eps0.ckpt\"\n",
        "# model_path = \"resnet18_l2_eps0_5.ckpt\"\n",
        "# model_path = \"resnet18_l2_eps1.ckpt\"\n",
        "model_path = \"resnet18_l2_eps3.ckpt\"\n",
        "# model_path = \"resnet18_l2_eps5.ckpt\"\n",
        "\n",
        "full_model_path = \"/content/drive/MyDrive/Adversarial Attacks/Robust ImageNet Transfer Models/\" + model_path\n",
        "model, _ = make_and_restore_model(arch = resnet18(False), dataset = dataset, resume_path = full_model_path, add_custom_forward=False, pytorch_pretrained=False)\n",
        "checkpoint = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG_gB0_92lgZ",
        "outputId": "483ff858-1db9-4e01-871d-61989e8ebac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Replacing the last layer with 1 hidden layers and 1 classification layer that fits the imagenet dataset.]\n"
          ]
        }
      ],
      "source": [
        "# if not args.no_replace_last_layer and not args.eval_only:\n",
        "print(f'[Replacing the last layer with {args.additional_hidden} '\n",
        "      f'hidden layers and 1 classification layer that fits the {args.dataset} dataset.]')\n",
        "while hasattr(model, 'model'):\n",
        "    model = model.model\n",
        "model = ft(\"resnet\", model, 2, False)\n",
        "model, checkpoint = model_utils.make_and_restore_model(arch=model, dataset=imagenet,\n",
        "                                                        add_custom_forward=args.additional_hidden > 0 or False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrUGGpSK0ybR",
        "outputId": "fb48e605-de3e-4c7d-8c7b-2c50145289b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18/af9f2089-c4b7-4754-9412-241760d5ebf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch:0 | Loss 0.6663 | NatPrec1 59.606 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  3.57it/s]\n",
            "Val Epoch:0 | Loss 0.5233 | NatPrec1 82.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  3.30it/s]\n",
            "Train Epoch:1 | Loss 0.4050 | NatPrec1 83.251 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  4.12it/s]\n",
            "Val Epoch:1 | Loss 0.3821 | NatPrec1 86.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  8.62it/s]\n",
            "Train Epoch:2 | Loss 0.2674 | NatPrec1 89.163 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  4.60it/s]\n",
            "Val Epoch:2 | Loss 0.3246 | NatPrec1 86.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.40it/s]\n",
            "Train Epoch:3 | Loss 0.1977 | NatPrec1 92.611 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  4.85it/s]\n",
            "Val Epoch:3 | Loss 0.3111 | NatPrec1 86.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.41it/s]\n",
            "Train Epoch:4 | Loss 0.1531 | NatPrec1 96.059 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:03<00:00,  2.07it/s]\n",
            "Val Epoch:4 | Loss 0.2939 | NatPrec1 86.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  6.58it/s]\n",
            "Train Epoch:5 | Loss 0.1197 | NatPrec1 96.552 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:03<00:00,  2.19it/s]\n",
            "Val Epoch:5 | Loss 0.3286 | NatPrec1 84.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.34it/s]\n",
            "Train Epoch:6 | Loss 0.0949 | NatPrec1 97.537 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  4.52it/s]\n",
            "Val Epoch:6 | Loss 0.3406 | NatPrec1 86.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  4.55it/s]\n",
            "Train Epoch:7 | Loss 0.0773 | NatPrec1 99.015 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  4.84it/s]\n",
            "Val Epoch:7 | Loss 0.3284 | NatPrec1 86.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.51it/s]\n",
            "Train Epoch:8 | Loss 0.0613 | NatPrec1 99.015 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]\n",
            "Val Epoch:8 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.41it/s]\n",
            "Train Epoch:9 | Loss 0.0457 | NatPrec1 99.507 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  3.50it/s]\n",
            "Val Epoch:9 | Loss 0.3337 | NatPrec1 86.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  6.57it/s]\n",
            "Train Epoch:10 | Loss 0.0329 | NatPrec1 100.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  3.55it/s]\n",
            "Val Epoch:10 | Loss 0.3472 | NatPrec1 84.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  6.51it/s]\n",
            "Train Epoch:11 | Loss 0.0313 | NatPrec1 100.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  4.33it/s]\n",
            "Val Epoch:11 | Loss 0.3676 | NatPrec1 84.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.30it/s]\n",
            "Train Epoch:12 | Loss 0.0293 | NatPrec1 100.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  4.88it/s]\n",
            "Val Epoch:12 | Loss 0.4038 | NatPrec1 84.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.39it/s]\n",
            "Train Epoch:13 | Loss 0.0298 | NatPrec1 99.507 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  4.36it/s]\n",
            "Val Epoch:13 | Loss 0.4118 | NatPrec1 84.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  8.30it/s]\n",
            "Train Epoch:14 | Loss 0.0255 | NatPrec1 99.507 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  4.81it/s]\n",
            "Val Epoch:14 | Loss 0.3949 | NatPrec1 84.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.41it/s]\n",
            "Train Epoch:15 | Loss 0.0245 | NatPrec1 100.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  4.90it/s]\n",
            "Val Epoch:15 | Loss 0.3943 | NatPrec1 86.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.90it/s]\n",
            "Train Epoch:16 | Loss 0.0220 | NatPrec1 100.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:02<00:00,  2.85it/s]\n",
            "Val Epoch:16 | Loss 0.3963 | NatPrec1 86.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  5.67it/s]\n",
            "Train Epoch:17 | Loss 0.0227 | NatPrec1 100.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:02<00:00,  3.41it/s]\n",
            "Val Epoch:17 | Loss 0.3914 | NatPrec1 86.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.14it/s]\n",
            "Train Epoch:18 | Loss 0.0420 | NatPrec1 99.015 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  4.95it/s]\n",
            "Val Epoch:18 | Loss 0.3859 | NatPrec1 84.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.59it/s]\n",
            "Train Epoch:19 | Loss 0.0117 | NatPrec1 100.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 7/7 [00:01<00:00,  5.21it/s]\n",
            "Val Epoch:19 | Loss 0.3843 | NatPrec1 84.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:00:53.830737\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  st = datetime.datetime.now()\n",
        "\n",
        "  out_store = cox.store.Store(OUT_DIR)\n",
        "\n",
        "  train.train_model(args, model, (train_loader, val_loader), store=out_store)\n",
        "\n",
        "  end = datetime.datetime.now()\n",
        "  total = end - st\n",
        "  print(total)\n",
        "  out_store.close()\n",
        "except Exception as e:\n",
        "  out_store.close()\n",
        "  print(f\"model did not train to completion. \\n error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjSQYRGrU8s4"
      },
      "source": [
        "# Experiment Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq3oEx1wxG2R"
      },
      "source": [
        "EXP IDs\n",
        "\n",
        "\n",
        "ResNet18 L2 eps= 0.0\n",
        "808d86b6-86d7-40c6-a58e-de2a020151a3\n",
        "\n",
        "ResNet18 L2 eps= 0.5\n",
        "a8fb44ca-b61a-44bb-b6af-ab6492f4efb3\n",
        "\n",
        "ResNet18 L2 eps= 1.0\n",
        "8d4879b4-6733-489b-8aa4-d6e2ad1e083a\n",
        "\n",
        "ResNet18 L2 eps= 3.0\n",
        "af9f2089-c4b7-4754-9412-241760d5ebf5\n",
        "\n",
        "ResNet18 L2 eps= 5.0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-kIrxTLU8JR"
      },
      "outputs": [],
      "source": [
        "EXP = \"af9f2089-c4b7-4754-9412-241760d5ebf5\"\n",
        "BEST = \"checkpoint.pt.best\"\n",
        "LATEST = \"checkpoint.pt.latest\"\n",
        "FIRST = \"0_checkpoint.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpZVPNdjUhxY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "621ad4b3-dec6-48e5-87d4-855810153cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:00<00:00, 88.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: exp_id 68d224df-7845-44cd-bc7a-338de46559d3 has no table 'logs'. Skipping.\n",
            "Warning: exp_id 61cdeb03-e4be-4a2c-b5eb-ae1349a0be0f has no table 'logs'. Skipping.\n",
            "Warning: exp_id 6d1bdb9b-554b-45fe-9193-c275cce79455 has no table 'logs'. Skipping.\n",
            "Warning: exp_id 5a2181df-d2e0-43ae-9f88-2849bdf30379 has no table 'logs'. Skipping.\n",
            "Warning: exp_id bd9428a5-255b-4e13-9683-f1010fa9d8ec has no table 'logs'. Skipping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   epoch  nat_prec1  adv_prec1  nat_loss  adv_loss  train_prec1  train_loss  \\\n",
              "0      1       82.0       -1.0  0.523324      -1.0    59.605911    0.666254   \n",
              "1      2       86.0       -1.0  0.382055      -1.0    83.251228    0.404987   \n",
              "2      3       86.0       -1.0  0.324613      -1.0    89.162560    0.267388   \n",
              "3      4       86.0       -1.0  0.311120      -1.0    92.610832    0.197719   \n",
              "4      5       86.0       -1.0  0.293921      -1.0    96.059113    0.153131   \n",
              "\n",
              "        time                                exp_id  \n",
              "0   2.617564  af9f2089-c4b7-4754-9412-241760d5ebf5  \n",
              "1   5.870825  af9f2089-c4b7-4754-9412-241760d5ebf5  \n",
              "2   9.285315  af9f2089-c4b7-4754-9412-241760d5ebf5  \n",
              "3  11.265604  af9f2089-c4b7-4754-9412-241760d5ebf5  \n",
              "4  15.314352  af9f2089-c4b7-4754-9412-241760d5ebf5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f7b3227-b8c2-4f23-8b1d-ac04c68fb1a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>nat_prec1</th>\n",
              "      <th>adv_prec1</th>\n",
              "      <th>nat_loss</th>\n",
              "      <th>adv_loss</th>\n",
              "      <th>train_prec1</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>time</th>\n",
              "      <th>exp_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>82.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.523324</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>59.605911</td>\n",
              "      <td>0.666254</td>\n",
              "      <td>2.617564</td>\n",
              "      <td>af9f2089-c4b7-4754-9412-241760d5ebf5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>86.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.382055</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>83.251228</td>\n",
              "      <td>0.404987</td>\n",
              "      <td>5.870825</td>\n",
              "      <td>af9f2089-c4b7-4754-9412-241760d5ebf5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>86.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.324613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>89.162560</td>\n",
              "      <td>0.267388</td>\n",
              "      <td>9.285315</td>\n",
              "      <td>af9f2089-c4b7-4754-9412-241760d5ebf5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>86.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.311120</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>92.610832</td>\n",
              "      <td>0.197719</td>\n",
              "      <td>11.265604</td>\n",
              "      <td>af9f2089-c4b7-4754-9412-241760d5ebf5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>86.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.293921</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>96.059113</td>\n",
              "      <td>0.153131</td>\n",
              "      <td>15.314352</td>\n",
              "      <td>af9f2089-c4b7-4754-9412-241760d5ebf5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f7b3227-b8c2-4f23-8b1d-ac04c68fb1a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f7b3227-b8c2-4f23-8b1d-ac04c68fb1a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f7b3227-b8c2-4f23-8b1d-ac04c68fb1a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "reader = CollectionReader(OUT_DIR)\n",
        "logs = reader.df('logs')\n",
        "reader.close()\n",
        "logs = logs[logs.exp_id == EXP]\n",
        "logs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCWlOybvV2z4"
      },
      "outputs": [],
      "source": [
        "# validation accuracies and loss\n",
        "nat_prec1 = logs.nat_prec1\n",
        "adv_prec1 = logs.adv_prec1\n",
        "nat_loss = logs.nat_loss\n",
        "adv_loss = logs.adv_loss\n",
        "\n",
        "# training accuracies and losses --> here, we only have adversarial accuracies and losses...do you understand why?\n",
        "train_prec1 = logs.train_prec1\n",
        "train_loss = logs.train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K8waGbJiW72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2d55f23a-aee4-449c-d1e6-d82717fbf32a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"d136e41b-48c1-4cc7-bab2-d21e890b1d8b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d136e41b-48c1-4cc7-bab2-d21e890b1d8b\")) {                    Plotly.newPlot(                        \"d136e41b-48c1-4cc7-bab2-d21e890b1d8b\",                        [{\"line\":{\"color\":\"red\"},\"mode\":\"lines+markers\",\"name\":\"train_loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[0.6662540413769595,0.40498742152904643,0.267388215352749,0.197719359100599,0.15313133957057162,0.11970355196539405,0.09492873411460463,0.07732739930816472,0.06126859833674478,0.04573261534125347,0.03288215428150346,0.03130867387273629,0.02931350329202678,0.029811921157860403,0.025497923215181368,0.024538204624441458,0.021989082607894842,0.02271077697958999,0.042021029504942777,0.011651723391004825],\"type\":\"scatter\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"nat_loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[0.5233238625526428,0.3820546567440033,0.32461329698562624,0.3111198890209198,0.29392111897468565,0.3286219549179077,0.3405689299106598,0.3283769738674164,0.31136518001556396,0.3336739492416382,0.347186381816864,0.367585289478302,0.40375514268875123,0.4118341094255447,0.3949461531639099,0.3943350076675415,0.3963192403316498,0.3914261627197266,0.38591108918190004,0.38434480905532836],\"type\":\"scatter\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"adv_loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"font\":{\"size\":20},\"yaxis\":{\"title\":{\"text\":\"CE Loss\"}},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"hovermode\":\"x\",\"plot_bgcolor\":\"rgba(0, 0, 0, 0)\",\"paper_bgcolor\":\"rgba(0, 0, 0, 0)\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d136e41b-48c1-4cc7-bab2-d21e890b1d8b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "losses = ['train_loss', 'nat_loss', 'adv_loss']\n",
        "\n",
        "scatter = []\n",
        "for i, loss in enumerate(losses):\n",
        "  scatter = scatter + measurement_scatter(logs[loss], logs.epoch, logs[loss], logs[loss], loss, loss, color=colors[i])\n",
        "\n",
        "\n",
        "fig = go.Figure(scatter)\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_title='CE Loss',\n",
        "    xaxis_title='Epoch',\n",
        "    hovermode=\"x\",\n",
        "    plot_bgcolor='rgba(0, 0, 0, 0)',\n",
        "    paper_bgcolor='rgba(0, 0, 0, 0)',\n",
        "    font={'size': 20}\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsssUPVmY9Fi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "63009054-c6e0-4795-b475-f8aa7375e0ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: adv_loss...\n",
            "Accuracy: adv_loss...\n",
            "Accuracy: adv_loss...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"75eede9e-c638-48ce-95db-3831790dce00\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"75eede9e-c638-48ce-95db-3831790dce00\")) {                    Plotly.newPlot(                        \"75eede9e-c638-48ce-95db-3831790dce00\",                        [{\"line\":{\"color\":\"red\"},\"mode\":\"lines+markers\",\"name\":\"train_prec1\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[59.60591125488281,83.25122833251953,89.16255950927734,92.61083221435547,96.05911254882812,96.55171966552734,97.53694152832031,99.01477813720703,99.01477813720703,99.50738525390625,100.0,100.0,100.0,99.50738525390625,99.50738525390625,100.0,100.0,100.0,99.01477813720703,100.0],\"type\":\"scatter\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"nat_prec1\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[82.0,86.0,86.0,86.0,86.0,84.0,86.0,86.0,88.0,86.0,84.0,84.0,84.0,84.0,84.0,86.0,86.0,86.0,84.0,84.0],\"type\":\"scatter\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"adv_prec1\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"font\":{\"size\":20},\"yaxis\":{\"title\":{\"text\":\"Accuracy\"}},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"hovermode\":\"x\",\"plot_bgcolor\":\"rgba(0, 0, 0, 0)\",\"paper_bgcolor\":\"rgba(0, 0, 0, 0)\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('75eede9e-c638-48ce-95db-3831790dce00');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "accuracies = ['train_prec1', 'nat_prec1', 'adv_prec1']\n",
        "\n",
        "scatter = []\n",
        "for i, acc in enumerate(accuracies):\n",
        "  print(f'Accuracy: {loss}...')\n",
        "  scatter = scatter + measurement_scatter(logs[acc], logs.epoch, logs[acc], logs[acc], acc, acc, color=colors[i])\n",
        "\n",
        "\n",
        "fig = go.Figure(scatter)\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_title='Accuracy',\n",
        "    xaxis_title='Epoch',\n",
        "    hovermode=\"x\",\n",
        "    plot_bgcolor='rgba(0, 0, 0, 0)',\n",
        "    paper_bgcolor='rgba(0, 0, 0, 0)',\n",
        "    font={'size': 20}\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T5TUDcDEQe2"
      },
      "source": [
        "#Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK8EHvR2mFb6"
      },
      "outputs": [],
      "source": [
        "resume_path=OUT_DIR + \"/\" + EXP + \"/\" + BEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnwnkvM-l7P-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab4b61a-6c13-403e-81c1-a21994273b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> loading checkpoint '/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18/af9f2089-c4b7-4754-9412-241760d5ebf5/checkpoint.pt.best'\n",
            "=> loaded checkpoint '/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18/af9f2089-c4b7-4754-9412-241760d5ebf5/checkpoint.pt.best' (epoch 9)\n"
          ]
        }
      ],
      "source": [
        "from robustness import imagenet_models # or cifar_models\n",
        "from robustness.datasets import ImageNet\n",
        "\n",
        "model = AttackerModel(resnet18(), imagenet)\n",
        "\n",
        "while hasattr(model, 'model'):\n",
        "    model = model.model\n",
        "model = ft(\"resnet\", model, 2, False)\n",
        "\n",
        "model, checkpoint = model_utils.make_and_restore_model(arch=model, dataset=imagenet,\n",
        "                                                        add_custom_forward=args.additional_hidden > 0 or False,\n",
        "                                                       resume_path = resume_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVvImGF3D2fe"
      },
      "source": [
        "##Evaluating robust model with constaint: 2, ϵ-test: 0, 0.25, 0.5, 1.0, 2.0, and attack_steps: [20, 200]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgoMXyajD2ff"
      },
      "source": [
        "####ϵ-test: 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmmJkY4d1B-D"
      },
      "outputs": [],
      "source": [
        "# from pyngrok import ngrok\n",
        "\n",
        "# # Set the ngrok authtoken (only needed for free users)\n",
        "# NGROK_AUTH_TOKEN = \"23Qif7HL0weneUkOUXkCzY3ZRQG_3gPVLhxnC1kRDVRqWezY7\"\n",
        "\n",
        "# ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# # Open a tunnel to the TensorBoard port\n",
        "# public_url = ngrok.connect(addr=\"6006\", proto=\"http\")\n",
        "\n",
        "# public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjcLWNDTD2ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60aa3e93-04c9-46c1-c407-f27f66c79722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation args: {\n",
            "  \"adv_eval\": 1,\n",
            "  \"eval_only\": 1,\n",
            "  \"use_best\": true,\n",
            "  \"random_restarts\": 0,\n",
            "  \"constraint\": \"2\",\n",
            "  \"eps\": 0.0,\n",
            "  \"attack_steps\": 20,\n",
            "  \"attack_lr\": 0.0125,\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18fourier_eval/\"\n",
            "}\n",
            "evaluating robust model with constaint: 2, eps: 0, and attack steps: 20\n",
            "test results dir: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0/robustness\n",
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0/robustness/dc84af46-9285-4025-998c-ac594838953b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val Epoch:0 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.43it/s]\n",
            "Val Epoch:0 | Loss 0.3114 | AdvPrec1 88.000 | AdvPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:01<00:00,  1.08it/s]\n"
          ]
        }
      ],
      "source": [
        "eval_args.__setattr__('constraint', '2')\n",
        "eval_args.__setattr__('eps', 0.0)\n",
        "print(f'evaluation args: {eval_args}')\n",
        "\n",
        "#evals on robust model\n",
        "TEST_OUT = OUT_DIR + L2_EVAL.format(.5, 0) + 'robustness'\n",
        "evaluate_robust_model(eval_args, model, TEST_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RZlZ-PhsSn7"
      },
      "outputs": [],
      "source": [
        "# !tensorboard --logdir=/content/drive/MyDrive/Adversarial\\ Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0/robustness/5c987dcd-bdcb-4666-9874-fd2a30f49584 serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doOuecqSAP6P"
      },
      "source": [
        "####ϵ-test: 0.25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDRqDnq8D2fg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb87d8c-f38f-46a4-a769-e7a78d5f07ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation args: {\n",
            "  \"adv_eval\": 1,\n",
            "  \"eval_only\": 1,\n",
            "  \"use_best\": true,\n",
            "  \"random_restarts\": 0,\n",
            "  \"constraint\": \"2\",\n",
            "  \"eps\": 0.25,\n",
            "  \"attack_steps\": 20,\n",
            "  \"attack_lr\": 0.0,\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0/robustness\"\n",
            "}\n",
            "evaluating robust model with constaint: 2, eps: 1/4, and attack steps: 20\n",
            "test results dir: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0.25/robustness\n",
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0.25/robustness/e8e4752c-bde2-44dc-b2fb-4f4e8a6b8857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val Epoch:0 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00, 10.01it/s]\n",
            "Val Epoch:0 | Loss 0.6399 | AdvPrec1 76.000 | AdvPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\n"
          ]
        }
      ],
      "source": [
        "eval_args.__setattr__('constraint', '2')\n",
        "eval_args.__setattr__('eps', 0.25)\n",
        "print(f'evaluation args: {eval_args}')\n",
        "\n",
        "#evals on robust model\n",
        "TEST_OUT = OUT_DIR + L2_EVAL.format(.5, 0.25) + 'robustness'\n",
        "evaluate_robust_model(eval_args, model, TEST_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrCzX0JlwmXd"
      },
      "outputs": [],
      "source": [
        "# !tensorboard --logdir=/content/drive/MyDrive/Adversarial\\ Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0.25/robustness/7d3e5fe7-55e2-4bfe-a73c-514a55fee786 serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoSrzVb4AT6P"
      },
      "source": [
        "####ϵ-test: 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wja3le3AD2fg",
        "outputId": "657c57c9-67ce-4e7b-f903-eb8767a87367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation args: {\n",
            "  \"adv_eval\": 1,\n",
            "  \"eval_only\": 1,\n",
            "  \"use_best\": true,\n",
            "  \"random_restarts\": 0,\n",
            "  \"constraint\": \"2\",\n",
            "  \"eps\": 0.5,\n",
            "  \"attack_steps\": 20,\n",
            "  \"attack_lr\": 0.03125,\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0.25/robustness\"\n",
            "}\n",
            "evaluating robust model with constaint: 2, eps: 1/2, and attack steps: 20\n",
            "test results dir: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0.5/take_one\n",
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0.5/take_one/42c03c88-4ca6-4b06-b744-61cfbb4ebd07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val Epoch:0 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  7.14it/s]\n",
            "Val Epoch:0 | Loss 1.1660 | AdvPrec1 58.000 | AdvPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n"
          ]
        }
      ],
      "source": [
        "eval_args.__setattr__('constraint', '2')\n",
        "eval_args.__setattr__('eps', 0.5)\n",
        "print(f'evaluation args: {eval_args}')\n",
        "\n",
        "#evals on robust model\n",
        "TEST_OUT = OUT_DIR + L2_EVAL.format(.5, 0.5) + 'take_one'\n",
        "evaluate_robust_model(eval_args, model, TEST_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWjpE2gSp73e"
      },
      "outputs": [],
      "source": [
        "# !tensorboard --logdir=/content/drive/MyDrive/Adversarial\\ Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0.5/take_one/7292cdd1-37b7-40f6-b357-4ed01bb05c6c serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aGNomhRAUJo"
      },
      "source": [
        "####ϵ-test: 1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOIEB7xrD2fh",
        "outputId": "055a5fa1-7e94-4d48-d9f3-5d05c87cd82a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation args: {\n",
            "  \"adv_eval\": 1,\n",
            "  \"eval_only\": 1,\n",
            "  \"use_best\": true,\n",
            "  \"random_restarts\": 0,\n",
            "  \"constraint\": \"2\",\n",
            "  \"eps\": 1.0,\n",
            "  \"attack_steps\": 20,\n",
            "  \"attack_lr\": 0.0625,\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_0.5/take_one\"\n",
            "}\n",
            "evaluating robust model with constaint: 2, eps: 1, and attack steps: 20\n",
            "test results dir: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_1.0/test_1.0\n",
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_1.0/test_1.0/92661294-d643-43b5-b83e-db642fada8fe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val Epoch:0 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  4.55it/s]\n",
            "Val Epoch:0 | Loss 2.7679 | AdvPrec1 22.000 | AdvPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]\n"
          ]
        }
      ],
      "source": [
        "eval_args.__setattr__('constraint', '2')\n",
        "eval_args.__setattr__('eps', 1.0)\n",
        "print(f'evaluation args: {eval_args}')\n",
        "\n",
        "#evals on robust model\n",
        "TEST_OUT = OUT_DIR + L2_EVAL.format(.5, 1.0) + 'test_1.0'\n",
        "evaluate_robust_model(eval_args, model, TEST_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvQdikHRr6Vt"
      },
      "outputs": [],
      "source": [
        "# !tensorboard --logdir=/content/drive/MyDrive/Adversarial\\ Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_1.0/test_1.0/d025d1f7-da12-4911-95f8-c58fb3eaa7e4 serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8_TOnHfAUa9"
      },
      "source": [
        "####ϵ-test: 2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT6JT9vjD2fh",
        "outputId": "26a9cd5d-c6a5-4fa6-bc30-731995d09a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation args: {\n",
            "  \"adv_eval\": 1,\n",
            "  \"eval_only\": 1,\n",
            "  \"use_best\": true,\n",
            "  \"random_restarts\": 0,\n",
            "  \"constraint\": \"2\",\n",
            "  \"eps\": 2.0,\n",
            "  \"attack_steps\": 20,\n",
            "  \"attack_lr\": 0.125,\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_1.0/test_1.0\"\n",
            "}\n",
            "evaluating robust model with constaint: 2, eps: 2, and attack steps: 20\n",
            "test results dir: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_2.0/eps_2.0\n",
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_2.0/eps_2.0/08ac2667-e0cb-4ae1-b2c8-c37cc2a03952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val Epoch:0 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  7.13it/s]\n",
            "Val Epoch:0 | Loss 5.5404 | AdvPrec1 0.000 | AdvPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]\n"
          ]
        }
      ],
      "source": [
        "eval_args.__setattr__('constraint', '2')\n",
        "eval_args.__setattr__('eps', 2.0)\n",
        "print(f'evaluation args: {eval_args}')\n",
        "\n",
        "#evals on robust model\n",
        "TEST_OUT = OUT_DIR + L2_EVAL.format(.5, 2.0) + 'eps_2.0'\n",
        "evaluate_robust_model(eval_args, model, TEST_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM0L0cB9yInA"
      },
      "outputs": [],
      "source": [
        "# !tensorboard --logdir=/content/drive/MyDrive/Adversarial\\ Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_2.0/eps_2.0/dc6118a3-cbea-4d48-a059-1cb4412730b8 serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKMZOUPdD2fh"
      },
      "source": [
        "##Evaluating robust model with constaint: ∞, ϵ-test: 0, 8/255, 16/255, and attack_steps: [20, 200]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opsxPdb-4nhv"
      },
      "outputs": [],
      "source": [
        "# from pyngrok import ngrok\n",
        "\n",
        "# # Set the ngrok authtoken (only needed for free users)\n",
        "# NGROK_AUTH_TOKEN = \"23Qif7HL0weneUkOUXkCzY3ZRQG_3gPVLhxnC1kRDVRqWezY7\"\n",
        "\n",
        "# ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# # Open a tunnel to the TensorBoard port\n",
        "# public_url = ngrok.connect(addr=\"6006\", proto=\"http\")\n",
        "\n",
        "# public_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjvKjRETBQ91"
      },
      "source": [
        "####ϵ-test: 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg9XEEa9D2fi",
        "outputId": "af400e48-5503-465c-a3be-e03b5cd2a28b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation args: {\n",
            "  \"adv_eval\": 1,\n",
            "  \"eval_only\": 1,\n",
            "  \"use_best\": true,\n",
            "  \"random_restarts\": 0,\n",
            "  \"constraint\": \"inf\",\n",
            "  \"eps\": 0,\n",
            "  \"attack_steps\": 20,\n",
            "  \"attack_lr\": 0.25,\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l2_eval_0.5_2.0/eps_2.0\"\n",
            "}\n",
            "evaluating robust model with constaint: inf, eps: 0, and attack steps: 20\n",
            "test results dir: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0/linf\n",
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0/linf/7e3ebca9-3a44-4003-910d-85899e5de337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val Epoch:0 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00, 10.02it/s]\n",
            "Val Epoch:0 | Loss 0.3114 | AdvPrec1 88.000 | AdvPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n"
          ]
        }
      ],
      "source": [
        "eval_args.__setattr__('constraint', 'inf')\n",
        "eval_args.__setattr__('eps', 0)\n",
        "print(f'evaluation args: {eval_args}')\n",
        "\n",
        "#evals on robust model\n",
        "TEST_L_INF_OUT = OUT_DIR + L_INF_EVAL.format(8/255, 0) + 'linf'\n",
        "evaluate_robust_model(eval_args, model, TEST_L_INF_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlhHK_gKo_xU"
      },
      "outputs": [],
      "source": [
        "# !tensorboard --logdir=/content/drive/MyDrive/Adversarial\\ Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0/linf/11f4508d-1e4e-40fc-bc17-4a990637ef36 serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vaclb0CGBbZs"
      },
      "source": [
        "####ϵ-test: 8/255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjQFGN6ID2fi",
        "outputId": "6796f509-672c-4f0a-f82f-323f072b5b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation args: {\n",
            "  \"adv_eval\": 1,\n",
            "  \"eval_only\": 1,\n",
            "  \"use_best\": true,\n",
            "  \"random_restarts\": 0,\n",
            "  \"constraint\": \"inf\",\n",
            "  \"eps\": 0.03137254901960784,\n",
            "  \"attack_steps\": 20,\n",
            "  \"attack_lr\": 0.0,\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0/linf\"\n",
            "}\n",
            "evaluating robust model with constaint: inf, eps: 8/255, and attack steps: 20\n",
            "test results dir: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0.03137254901960784/linf\n",
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0.03137254901960784/linf/b53eec79-1859-419f-b021-450e6c251e43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val Epoch:0 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00, 10.33it/s]\n",
            "Val Epoch:0 | Loss 7.7243 | AdvPrec1 0.000 | AdvPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]\n"
          ]
        }
      ],
      "source": [
        "eval_args.__setattr__('constraint', 'inf')\n",
        "eval_args.__setattr__('eps', 8/255)\n",
        "print(f'evaluation args: {eval_args}')\n",
        "\n",
        "#evals on robust model\n",
        "TEST_L_INF_OUT = OUT_DIR + L_INF_EVAL.format(8/255, 8/255) + 'linf'\n",
        "evaluate_robust_model(eval_args, model, TEST_L_INF_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5g3xvDRTsX_T"
      },
      "outputs": [],
      "source": [
        "# !tensorboard --logdir=/content/drive/MyDrive/Adversarial\\ Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0.03137254901960784/linf/20696687-fdf7-43f1-82e8-0fd0151b0d58 serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNFVaLpqBbwJ"
      },
      "source": [
        "####ϵ-test: 16/255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsQ_iNNXD2fj",
        "outputId": "b711d812-7930-45c7-c876-200cedb230c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation args: {\n",
            "  \"adv_eval\": 1,\n",
            "  \"eval_only\": 1,\n",
            "  \"use_best\": true,\n",
            "  \"random_restarts\": 0,\n",
            "  \"constraint\": \"inf\",\n",
            "  \"eps\": 0.06274509803921569,\n",
            "  \"attack_steps\": 20,\n",
            "  \"attack_lr\": 0.00392156862745098,\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0.03137254901960784/linf\"\n",
            "}\n",
            "evaluating robust model with constaint: inf, eps: 16/255, and attack steps: 20\n",
            "test results dir: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0.06274509803921569/linf\n",
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0.06274509803921569/linf/608e2209-0b7d-4b48-a181-ba813e9a7bd6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val Epoch:0 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00, 10.12it/s]\n",
            "Val Epoch:0 | Loss 9.7705 | AdvPrec1 0.000 | AdvPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]\n"
          ]
        }
      ],
      "source": [
        "eval_args.__setattr__('constraint', 'inf')\n",
        "eval_args.__setattr__('eps', 16/255)\n",
        "print(f'evaluation args: {eval_args}')\n",
        "\n",
        "#evals on robust model\n",
        "TEST_L_INF_OUT = OUT_DIR + L_INF_EVAL.format(8/255, 16/255) +'linf'\n",
        "evaluate_robust_model(eval_args, model, TEST_L_INF_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsXxcBscuPOy"
      },
      "outputs": [],
      "source": [
        "# !tensorboard --logdir=/content/drive/MyDrive/Adversarial\\ Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0.06274509803921569/linf/30aa6236-19a0-4830-b9bb-fba0d691d7c1 serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVnh0x8-D2fj"
      },
      "source": [
        "##Evaluating robust model with constrain: unconstrained, ϵ-test: unconstrained, and attack_steps: [20, 100]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi_6gGelvhSV",
        "outputId": "77fbc0fa-5c61-4840-a059-451ef2c9d4f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://b137-35-240-181-35.ngrok-free.app\" -> \"http://localhost:6006\">"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set the ngrok authtoken (only needed for free users)\n",
        "NGROK_AUTH_TOKEN = \"23Qif7HL0weneUkOUXkCzY3ZRQG_3gPVLhxnC1kRDVRqWezY7\"\n",
        "\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open a tunnel to the TensorBoard port\n",
        "public_url = ngrok.connect(addr=\"6006\", proto=\"http\")\n",
        "\n",
        "public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8g41N2-D2fj",
        "outputId": "e7fa0ca4-5096-45ec-9e58-4af18dd36571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation args: {\n",
            "  \"adv_eval\": 1,\n",
            "  \"eval_only\": 1,\n",
            "  \"use_best\": true,\n",
            "  \"random_restarts\": 0,\n",
            "  \"constraint\": \"unconstrained\",\n",
            "  \"eps\": 0.1,\n",
            "  \"attack_steps\": 20,\n",
            "  \"attack_lr\": 0.00784313725490196,\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18l_inf_eval_0.03137254901960784_0.06274509803921569/linf\"\n",
            "}\n",
            "evaluating robust model with constaint: unconstrained, eps: 1/10, and attack steps: 20\n",
            "test results dir: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18unconstrained_eval/unconstrainedyeaa\n",
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18unconstrained_eval/unconstrainedyeaa/f81255e9-c82d-44a6-94e3-5f14da48f583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val Epoch:0 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  6.85it/s]\n",
            "Val Epoch:0 | Loss 0.3765 | AdvPrec1 88.000 | AdvPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n"
          ]
        }
      ],
      "source": [
        "eval_args.__setattr__('constraint', 'unconstrained')\n",
        "eval_args.__setattr__('eps', 0.1) #eps-values not used\n",
        "print(f'evaluation args: {eval_args}')\n",
        "\n",
        "#evals on robust model\n",
        "TEST_UNCONSTRAINED_OUT = OUT_DIR + UNCONSTRAINED_EVAL + 'unconstrainedyeaa'\n",
        "evaluate_robust_model(eval_args, model, TEST_UNCONSTRAINED_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6F3qCEq3vhSW"
      },
      "outputs": [],
      "source": [
        "# !tensorboard --logdir=/content/drive/MyDrive/Adversarial\\ Attacks/robust_transfer_learning/resnet_18unconstrained_eval/unconstrainedyeaa/1458520a-efec-4c73-96f8-0ce62cbea338 serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfw-GOcsD2fk"
      },
      "source": [
        "##Evaluating robust model with constrain: random smooth, ϵ-test: random smooth and attack_steps: [20, 100]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od2xSiXwydjh"
      },
      "outputs": [],
      "source": [
        "# from pyngrok import ngrok\n",
        "\n",
        "# # Set the ngrok authtoken (only needed for free users)\n",
        "# NGROK_AUTH_TOKEN = \"23Qif7HL0weneUkOUXkCzY3ZRQG_3gPVLhxnC1kRDVRqWezY7\"\n",
        "\n",
        "# ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# # Open a tunnel to the TensorBoard port\n",
        "# public_url = ngrok.connect(addr=\"6006\", proto=\"http\")\n",
        "\n",
        "# public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLgK67fZD2fk",
        "outputId": "543ca092-96dd-4639-c385-895963795ee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation args: {\n",
            "  \"adv_eval\": 1,\n",
            "  \"eval_only\": 1,\n",
            "  \"use_best\": true,\n",
            "  \"random_restarts\": 0,\n",
            "  \"constraint\": \"random_smooth\",\n",
            "  \"eps\": 0.1,\n",
            "  \"attack_steps\": 20,\n",
            "  \"attack_lr\": 0.0125,\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18unconstrained_eval/unconstrainedyeaa\"\n",
            "}\n",
            "evaluating robust model with constaint: random_smooth, eps: 1/10, and attack steps: 20\n",
            "test results dir: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18random_eval/randomsmoothyeaaa\n",
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18random_eval/randomsmoothyeaaa/65fc89f4-bdd6-4dd9-995c-30677f6bda03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val Epoch:0 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  6.51it/s]\n",
            "Val Epoch:0 | Loss 0.6614 | AdvPrec1 56.000 | AdvPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:01<00:00,  1.57it/s]\n"
          ]
        }
      ],
      "source": [
        "eval_args.__setattr__('constraint', 'random_smooth')\n",
        "eval_args.__setattr__('eps', 0.1) #eps value not used\n",
        "print(f'evaluation args: {eval_args}')\n",
        "\n",
        "#evals on robust model\n",
        "TEST_RANDOM_OUT = OUT_DIR + RANDOM_EVAL + 'randomsmoothyeaaa'\n",
        "evaluate_robust_model(eval_args, model, TEST_RANDOM_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpG7KTgCyatS"
      },
      "outputs": [],
      "source": [
        "# !tensorboard --logdir=/content/drive/MyDrive/Adversarial\\ Attacks/robust_transfer_learning/resnet_18random_eval/randomsmoothyeaaa/90e42c70-baa0-40dc-8030-657abea311ac serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzGW7K-wD2fk"
      },
      "source": [
        "##Evaluating robust model with constrain: fourier, ϵ-test: fourier and attack_steps: [20, 100]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "ftSpsaxnImS0",
        "outputId": "6ae2cf15-3ef7-4ee9-a2be-7c210ab1708f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation args: {\n",
            "  \"adv_eval\": 1,\n",
            "  \"eval_only\": 1,\n",
            "  \"use_best\": true,\n",
            "  \"random_restarts\": 0,\n",
            "  \"constraint\": \"fourier\",\n",
            "  \"eps\": 0.1,\n",
            "  \"attack_steps\": 20,\n",
            "  \"attack_lr\": 0.0125,\n",
            "  \"out_dir\": \"/content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18random_eval/randomsmoothyeaaa\"\n",
            "}\n",
            "evaluating robust model with constaint: fourier, eps: 1/10, and attack steps: 20\n",
            "test results dir: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18fourier_eval/\n",
            "Logging in: /content/drive/MyDrive/Adversarial Attacks/robust_transfer_learning/resnet_18fourier_eval/ef325e89-df14-4956-a978-ea5c8dddaec6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val Epoch:0 | Loss 0.3114 | NatPrec1 88.000 | NatPrec5 100.000 | Reg term: 0.0 ||: 100%|██████████| 2/2 [00:00<00:00,  9.80it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-e0151a91213d>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#evals on robust model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mTEST_FOURIER_OUT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUT_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFOURIER_EVAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mevaluate_robust_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_FOURIER_OUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-1bd4ab6b4b99>\u001b[0m in \u001b[0;36mevaluate_robust_model\u001b[0;34m(eval_args, model, test_out_dir, attack_steps)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mtest_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_store_with_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_store\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mtest_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/robustness/robustness/train.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(args, model, loader, store)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eps'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attack_lr'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         adv_prec1, adv_loss = _model_loop(args, 'val', loader, \n\u001b[0m\u001b[1;32m    161\u001b[0m                                         model, None, 0, True, writer)\n\u001b[1;32m    162\u001b[0m     log_info = {\n",
            "\u001b[0;32m/content/robustness/robustness/train.py\u001b[0m in \u001b[0;36m_model_loop\u001b[0;34m(args, loop_type, loader, model, opt, epoch, adv, writer)\u001b[0m\n\u001b[1;32m    445\u001b[0m        \u001b[0;31m# measure data loading time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         output, final_inp = model(inp, target=target, make_adv=adv,\n\u001b[0m\u001b[1;32m    448\u001b[0m                                   **attack_kwargs)\n\u001b[1;32m    449\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/robustness/robustness/attacker.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, target, make_adv, with_latent, fake_relu, no_relu, with_image, **attacker_kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mprev_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0madv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattacker_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprev_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/robustness/robustness/attacker.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, target, constraint, eps, step_size, iterations, random_start, random_restarts, do_tqdm, targeted, custom_loss, should_normalize, orig_input, use_best, return_image, est_grad, mixed_precision, *_)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0madv_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0madv_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_adv_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madv_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/robustness/robustness/attacker.py\u001b[0m in \u001b[0;36mget_adv_examples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                         \u001b[0;34m'Shape of losses must match input!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/robustness/robustness/attack_steps.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \"\"\"\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mirfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monesided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRandomStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttackerStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'irfft'"
          ]
        }
      ],
      "source": [
        "eval_args.__setattr__('constraint', 'fourier')\n",
        "eval_args.__setattr__('eps', 0.1)\n",
        "print(f'evaluation args: {eval_args}')\n",
        "\n",
        "#evals on robust model\n",
        "TEST_FOURIER_OUT = OUT_DIR + FOURIER_EVAL\n",
        "evaluate_robust_model(eval_args, model, TEST_FOURIER_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29V4_fNSlJXx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Dy0BXTS8EQe3"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}